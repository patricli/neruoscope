{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patricli/neruoscope/blob/main/ux_improve_Modified_Interactive_Neuroscope_v22_1951.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ux-improve branch\n",
        "\n",
        "I have a few ideas to make the output from the neurosopce easier to use.\n",
        "\n",
        "- [X] Can we change the shape to make more stuff fit on a screen?\n",
        "- [ ] Could we exclude boring lines?\n",
        "- [ ] GIF?\n",
        "- [ ] ~~The gradio form needs a submit button. I don't want auto update on the text box.~~ Victor figures it's fast enough now that this should be low priority.\n",
        "- [ ] fix size of ui so it alows you to focus on speficic neu"
      ],
      "metadata": {
        "id": "XCOTmQJ4PB04"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQKWjK6cYjmK"
      },
      "source": [
        "# Interactive Neuroscope\n",
        "\n",
        "*This is an interactive accompaniment to [neuroscope.io](https://neuroscope.io) and to the [studying learned language features post](https://www.alignmentforum.org/posts/Qup9gorqpd9qKAEav/200-cop-in-mi-studying-learned-features-in-language-models) in [200 Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems)*\n",
        "\n",
        "There's a surprisingly rich ecosystem of easy ways to create interactive graphics, especially for ML systems. If you're trying to do mechanistic interpretability, the ability to do web dev and to both visualize data and interact with it seems high value! \n",
        "\n",
        "This is a demo of how you can combine HookedTransformer and [Gradio](https://gradio.app/) to create an interactive Neuroscope - a visualization of a neuron's activations on text that will dynamically update as you edit the text. I don't particularly claim that this code is any *good*, but the goal is to illustrate what quickly hacking together a custom visualisation (while knowing fuck all about web dev, like me) can look like! (And as such, I try to explain the basic web dev concepts I use)\n",
        "\n",
        "Note that you'll need to run the code yourself to get the interactive interface, so the cell at the bottom will be blank at first!\n",
        "\n",
        "To emphasise - the point of this notebook is to be a rough proof of concept that just about works, *not* to be the well executed ideal of interactively studying neurons! You are highly encouraged to write your own (and ideally, to [make a pull request](https://github.com/neelnanda-io/TransformerLens/pulls) with improvements!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0vq6kZSYjmM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYNs3wpzYjmM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zypQKl_YjmN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#if IN_COLAB:\n",
        "os.system(\"pip install git+https://github.com/neelnanda-io/TransformerLens.git\")\n",
        "os.system(\"pip install gradio\")\n",
        "os.system(\"pip install plotly\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/neelnanda-io/Easy-Transformer.git"
      ],
      "metadata": {
        "id": "QiQ2Le9hqL0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM3fBPM4YjmO"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformer_lens import HookedTransformer\n",
        "from transformer_lens.utils import to_numpy\n",
        "from IPython.display import HTML\n",
        "\n",
        "import transformer_lens.utils as utils\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some plotting code. Wrappers around Plotly, not important to understand."
      ],
      "metadata": {
        "id": "7jTudzt-p0u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heatmap(tensor, yaxis=\"\", xaxis=\"\", value=\"Activation\", **kwargs):\n",
        "  tensor = utils.to_numpy(tensor)\n",
        "  plot_kwargs = {\"color_continuous_scale\":\"RdBu\", \"color_continuous_midpoint\":0.0, \"labels\":{\"x\":xaxis, \"y\":yaxis, \"color\":value}}\n",
        "  plot_kwargs.update(kwargs)\n",
        "  return px.imshow(tensor, **plot_kwargs)"
      ],
      "metadata": {
        "id": "irNcAgo4001I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(tensor, yaxis=\"\", xaxis=\"\", **kwargs):\n",
        "  fig = heatmap(tensor, yaxis, xaxis, **kwargs)\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "NKvmfHy2pyQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.io as pio\n",
        "\n",
        "# Thanks to annoying rendering issues, Plotly graphics will either show up in \n",
        "# colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n",
        "pio.renderers.default = \"colab\""
      ],
      "metadata": {
        "id": "ZcDuiW5hrjJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU0BTvl9YjmO"
      },
      "source": [
        "## Extracting Model Activations\n",
        "\n",
        "We first write some code using HookedTransformer's cache to extract the neuron activations on a given layer and neuron, for a given text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMZl0_wKYjmP"
      },
      "outputs": [],
      "source": [
        "model_name = \"gpt2-small\"\n",
        "\n",
        "model = HookedTransformer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_layer_acts(text, layer):\n",
        "    # Hacky way to get out state from a single hook - we have a single element list and edit that list within the hook.\n",
        "    cache = {}\n",
        "\n",
        "    def caching_hook(act, hook):\n",
        "        cache[\"activation\"] = act[0, :, :]\n",
        "\n",
        "    model.run_with_hooks(\n",
        "        text, fwd_hooks=[(f\"blocks.{layer}.mlp.hook_post\", caching_hook)]\n",
        "    )\n",
        "    return to_numpy(cache[\"activation\"])"
      ],
      "metadata": {
        "id": "RFo8L2mtf9ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Default values"
      ],
      "metadata": {
        "id": "B5jy7JQOAnFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_text = \"The following is a list of powers of 10: 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000\"\n",
        "default_layer = 9\n",
        "default_min_neuron_index = 0\n",
        "default_max_neuron_index = model.cfg.d_mlp\n",
        "default_max_val=4\n",
        "default_min_val=-4"
      ],
      "metadata": {
        "id": "9BeQR4yHAmHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visual verification"
      ],
      "metadata": {
        "id": "EaYX34M0GmqJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7C14s08YjmP"
      },
      "source": [
        "We can run this function and verify that it gives vaguely sensible outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPgEDXQvYjmQ"
      },
      "outputs": [],
      "source": [
        "print(model.to_str_tokens(default_text))\n",
        "print(\"Default layer: \", get_layer_acts(default_text, default_layer))\n",
        "print(\"Shape: \", get_layer_acts(default_text, default_layer).shape)\n",
        "\n",
        "imshow(\n",
        "    get_layer_acts(default_text, default_layer).T[:][default_min_neuron_index:default_max_neuron_index],\n",
        "    height=max(200, (default_max_neuron_index - default_min_neuron_index)), width=800,\n",
        "    aspect=\"auto\", xaxis=\"Token\", yaxis=\"Position\",\n",
        "    x=[f'{i}: \"{token}\"' for i, token in enumerate(model.to_str_tokens(default_text))],\n",
        "    y=list(range(default_min_neuron_index, default_max_neuron_index))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEw2VnhhYjmR"
      },
      "source": [
        "## Visualizing Model Activations\n",
        "\n",
        "We now write some code to visualize the neuron activations on some text - we're going to hack something together which just does some string processing to make an HTML string, with each token element colored according to the intensity neuron activation. We normalize the neuron activations so they all lie in [0, 1]. You can do much better, but this is a useful proof of concept of what \"just hack stuff together\" can look like!\n",
        "\n",
        "I'll be keeping neuron 562 in layer 9 as a running example, as it seems to activate strongly on powers of 10.\n",
        "\n",
        "Note that this visualization is very sensitive to `max_val` and `min_val`! You can tune those to whatever seems reasonable for the distribution of neuron activations you care about - I generally default to `min_val=0` and `max_val` as the max activation across the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M1Uee2IYjmR"
      },
      "outputs": [],
      "source": [
        "def basic_neuron_vis(text, layer, min_neuron_index, max_neuron_index,max_val=None, min_val=None):\n",
        "    \"\"\"\n",
        "    text: The text to visualize\n",
        "    layer: The layer index\n",
        "    min_neuron_index: The minimum neuron index to show\n",
        "    max_neuron_index: The maximum neuron index to show\n",
        "\n",
        "    Returns a string of HTML that displays the text with each token colored according to its activation\n",
        "\n",
        "    Note: It's useful to be able to input a fixed max_val and min_val, because otherwise the colors will change as you edit the text, which is annoying.\n",
        "    \"\"\"\n",
        "    if layer is None:\n",
        "        return \"Please select a Layer\"\n",
        "    if min_neuron_index is None:\n",
        "        return \"Please select a minimum neuron index\"\n",
        "    if max_neuron_index is None:\n",
        "        return \"Please select a maximum neuron index\"\n",
        "\n",
        "    tokens = model.to_str_tokens(text)\n",
        "    acts = get_layer_acts(text, layer).T[:][min_neuron_index:max_neuron_index]    \n",
        "    if max_val is None:\n",
        "        max_val = acts.max()\n",
        "    if min_val is None:\n",
        "        min_val = acts.min()\n",
        "  \n",
        "\n",
        "    return heatmap(\n",
        "        acts,height=min(1200, max(500,(max_neuron_index - min_neuron_index))), width=800,\n",
        "        aspect=\"auto\", xaxis=\"Token\", yaxis=\"Position\",\n",
        "        x=[f'{i}: \"{token}\"' for i, token in enumerate(tokens)],\n",
        "        y=list(range(min_neuron_index, max_neuron_index)),zmin=min_val, zmax=max_val\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjk9odI1YjmS"
      },
      "source": [
        "## Create Interactive UI\n",
        "\n",
        "We now put all these together to create an interactive visualization in Gradio! \n",
        "\n",
        "The internal format is that there's a bunch of elements - Textboxes, Numbers, etc which the user can interact with and which return strings and numbers. And we can also define output elements that just display things - in this case, one which takes in an arbitrary HTML string. We call `input.change(update_function, inputs, output)` - this says \"if that input element changes, run the update function on the value of each of the elements in `inputs` and set the value of `output` to the output of the function\". As a bonus, this gives us live interactivity!\n",
        "\n",
        "This is also more complex than a typical Gradio intro example - I wanted to use custom HTML to display the nice colours, which made things much messier! Normally you could just make `out` into another Textbox and pass it a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpxWFrEAYjmT"
      },
      "outputs": [],
      "source": [
        "# The `with gr.Blocks() as demo:` syntax just creates a variable called demo containing all these components\n",
        "with gr.Blocks() as demo:\n",
        "    gr.HTML(value=f\"Hacky Interactive Neuroscope for {model_name}\")\n",
        "    # The input elements\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            text = gr.Textbox(label=\"Text\", value=default_text)\n",
        "            # Precision=0 makes it an int, otherwise it's a float\n",
        "            # Value sets the initial default value\n",
        "            layer = gr.Slider(\n",
        "                label=\"Layer\", value=default_layer, step=1, minimum=0, maximum=model.cfg.n_layers - 1)\n",
        "            min_neuron_index = gr.Slider(\n",
        "                label=\"Minimum neuron index\", value=default_min_neuron_index, \n",
        "                step=1, minimum=0, maximum=model.cfg.d_mlp)\n",
        "            max_neuron_index = gr.Slider(\n",
        "                label=\"Maximum neuron index\", value=default_max_neuron_index, \n",
        "                step=1, minimum=0, maximum=model.cfg.d_mlp)\n",
        "            max_val = gr.Number(label=\"Max Value\", value=default_max_val)\n",
        "            min_val = gr.Number(label=\"Min Value\", value=default_min_val)\n",
        "            inputs = [text, layer, min_neuron_index, max_neuron_index,max_val,min_val]\n",
        "        with gr.Column():\n",
        "            # The output element\n",
        "            out = gr.Plot(\n",
        "                basic_neuron_vis(default_text, default_layer, default_min_neuron_index, default_max_neuron_index))\n",
        "    for inp in inputs:\n",
        "        inp.change(basic_neuron_vis, inputs, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC7fWY0eYjmT"
      },
      "source": [
        "We can now launch our demo element, and we're done! The setting share=True even gives you a public link to the demo (though it just redirects to the backend run by this notebook, and will go away once you turn the notebook off!) Sharing makes it much slower, and can be turned off if you aren't in a colab.\n",
        "\n",
        "**Exercise:** Explore where this neuron does and does not activate. Is it just powers of ten? Just comma separated numbers? Numbers in any particular sequence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXeIKdmNYjmT"
      },
      "outputs": [],
      "source": [
        "demo.launch(share=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:#Hack to take advantage of colab pro longer inactive time\n",
        "   a=1+1"
      ],
      "metadata": {
        "id": "GnGRfZQHKsky"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}